{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import itertools as it\n",
    "from tidylib import tidy_document\n",
    "import tidylib\n",
    "import re\n",
    "\n",
    "# Override the tidylib defaults. The \"wrap\" parameter results in some weird bug.\n",
    "tidylib.BASE_OPTIONS = {\n",
    "    \"indent\": 1,           # Pretty; not too much of a performance hit\n",
    "    \"tidy-mark\": 0,        # No tidy meta tag in output\n",
    "#     \"wrap\": 0,             # No wrapping\n",
    "    \"alt-text\": \"\",        # Help ensure validation\n",
    "    \"doctype\": 'strict',   # Little sense in transitional for tool-generated markup...\n",
    "    \"force-output\": 1,     # May not get what you expect but you will get something\n",
    "    # Some unclosed <p> tags exist. We don't want to drop 'em. Just close them.\n",
    "    'drop_empty_paras': False \n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_link(url):\n",
    "    html_doc = requests.get(url).text\n",
    "    tidy_doc = tidy_document(html_doc, options={'drop_empty_paras': False, 'force_output': True})[0]\n",
    "    soup = BeautifulSoup(tidy_doc, 'html.parser')\n",
    "    return soup\n",
    "\n",
    "def consolidate_content(content):\n",
    "    content_container = BeautifulSoup(\"<div></div>\", 'html.parser')\n",
    "    for tag in content:\n",
    "        content_container.append(tag)\n",
    "    return content_container\n",
    "\n",
    "def get_content(clhs_soup):\n",
    "    without_head = [tag for tag in clhs_soup.body.hr.find_next_siblings()]\n",
    "    content = list(it.takewhile(lambda x: str(x) != '<hr/>', without_head))\n",
    "    return consolidate_content(content)\n",
    "\n",
    "def get_h2s(content):\n",
    "    return [tag for tag in content if tag.name == 'h2' and tag.a]\n",
    "\n",
    "def get_base_url(url):\n",
    "    return re.findall(\".*\\/\", url)[0]\n",
    "\n",
    "def build_link_from_h2(h2, base_url):\n",
    "    return get_base_url(url) + h2.a['href']\n",
    "\n",
    "def write_soup_tmp(soup):\n",
    "    with open(\"clhs.html\", \"w\") as f:\n",
    "        f.write(str(soup))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_with_sub_content(h2, base_url):\n",
    "    link = build_link_from_h2(h2, base_url)\n",
    "    soup = parse_link(link)\n",
    "    content = get_content(soup)\n",
    "    h2s = get_h2s(content)\n",
    "    for h2 in h2s:\n",
    "        h2.replace_with(replace_with_sub_content(h2, base_url))\n",
    "    return content\n",
    "\n",
    "def insert_sub_chapters(url):\n",
    "    base_url = get_base_url(url)\n",
    "    soup = parse_link(url)\n",
    "    content = get_content(soup)\n",
    "    h2s = get_h2s(content)\n",
    "    for h2 in h2s:\n",
    "        h2.replace_with(replace_with_sub_content(h2, base_url))\n",
    "    soup.hr.append(content)\n",
    "    return soup\n",
    "\n",
    "def fix_links(soup, base_url):\n",
    "    links = [a for a in soup.find_all('a') if a['href'] \n",
    "            and not a['href'].startswith('http://www.')\n",
    "            and not a['href'].startswith('../')]\n",
    "    for link in links:\n",
    "        link['href'] = base_url + link['href']\n",
    "\n",
    "def write_and_cleanup_clhs(soup, filepath):\n",
    "    with open(filepath, \"w\") as f:\n",
    "        # Remove double carriage return strings, resulting in bad formating for code examples.\n",
    "        f.write(str(soup).replace('\\r\\n', '\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"http://www.lispworks.com/documentation/HyperSpec/Body/06_a.htm\"\n",
    "soup = insert_sub_chapters(url)\n",
    "fix_links(soup, get_base_url(url))\n",
    "write_and_cleanup_clhs(soup, \"clhs.html\")\n",
    "soup"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
